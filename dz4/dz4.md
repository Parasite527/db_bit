# What is a vector database?


A vector database is a type of database that stores data as high-dimensional vectors, which are mathematical representations of features or attributes. Each vector has a certain number of dimensions, which can range from tens to thousands, depending on the complexity and granularity of the data. The vectors are usually generated by applying some kind of transformation or embedding function to the raw data, such as text, images, audio, video, and others. The embedding function can be based on various methods, such as machine learning models, word embeddings, feature extraction algorithms.

The main advantage of a vector database is that it allows for fast and accurate similarity search and retrieval of data based on their vector distance or similarity. This means that instead of using traditional methods of querying databases based on exact matches or predefined criteria, you can use a vector database to find the most similar or relevant data based on their semantic or contextual meaning.


# Use Cases for Vector Databases

Vector databases have many use cases across different domains and applications that involve natural language processing (NLP), computer vision (CV), recommendation systems (RS), and other areas that require semantic understanding and matching of data.

One use case for storing information in a vector database is to enable large language models (LLMs) to generate more relevant and coherent text based on an AI plugin.



# A little bit of history

### [Qdrant, an open source vector database startup, wants to help AI developers leverage unstructured data](https://techcrunch.com/2023/04/19/qdrant-an-open-source-vector-database-startup-wants-to-help-ai-developers-leverage-unstructured-data/)


![](Qdrant-founders.webp)
Image Credits: Qdrant. Founders -- left to right: [Fabrizio Schmidt](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://theorg.com/org/qdrant/org-chart/fabrizio-schmidt&ved=2ahUKEwjUoNyCo8OFAxVSKhAIHZdJBeMQFnoECB8QAQ&usg=AOvVaw3i3jytN7CG9gLccUFd6GT6), VP of Cloud; [Andrey Vasnetsov](https://theorg.com/org/qdrant/org-chart/andrey-vasnetsov), CTO; and [Andre Zayarni](https://theorg.com/org/qdrant/org-chart/andre-zayarni), CEO / 


For many, ChatGPT and the generative AI hype train signals the arrival of artificial intelligence into the mainstream. But while there’s little question of a seismic sea change these past six months in terms of public awareness, the growing demand for AI could be outpacing the infrastructure required to power the myriad use cases that are emerging — and this is something that German startup Qdrant is looking to address.

Founded out of Berlin in 2021, Qdrant is targeting AI software developers with an open source vector search engine and database for unstructured data, which is an integral part of AI application development particularly as it relates to using real-time data that hasn’t been categorized or labeled.

To help bring its technology deeper into the commercial sphere, Qdrant today announced a $7.5 million seed financing from lead investor Unusual Ventures, with participation from 42cap, IBB Ventures and a handful of angel backers, including Cloudera co-founder Amr Awadallah. This is in addition to the €2 million ($2.2 million) in pre-seed funding Qdrant raised last year.


....


“Vector databases are the natural extension of their (LLMs) capabilities,” Zayarni explained to TechCrunch. “The biggest limitation of GPT is that it ‘knows’ only about events that happened before the time the model was trained, but if it’s connected to a vector database, the virtual ‘memory’ of an LLM can be extended with real-time and real-world data.”

Investors have been taking note, too. Just last year, a similar proposition to Qdrant called Pinecone nabbed $28 million, though Zayarni considers Qdrant’s open source foundation as a major selling point for would-be customers.

“Engineers trust open source, and it will be hard for proprietary software to compete in this market if there is an OSS product with a similar — or even better — offering,” Zayarni said.


....


Zayarni said that Qdrant spent the better part of a month fine-tuning its pitch-deck for its seed funding round, and received its first term sheet on the second day after sending out its deck, which was followed by another term sheet two days after that.

“We had more than 20 VCs interested — almost all of them wanted to join as co-investors later — and we most probably would have received more offers,” Zayarni said. “But Unusual Ventures’ deep experience with OSS (open source software) and its model of being an active operational partner instead of just an investor were incredibly attractive to us, so we decided to go with them.”

Today’s funding news comes a couple of months after Qdrant launched its managed cloud offering, which is designed to help developers through one-click deployments, automated version upgrades, backups and a soon-to-launch database admin interface.

#### Also you can look up some historical notes [here](https://qdrant.tech/documentation/overview/vector-search/). 

# Intruments

Recommended to use python client in [documentation](https://qdrant.tech/documentation/) with composition with docker, but also provides the [OpenAPI](https://qdrant.github.io/qdrant/redoc/index.html) v3 specification to generate a client library in almost [any programming language](https://qdrant.tech/documentation/frameworks/langchain/). 


# Some technical info

Qdrant is a [vector search engine](https://db-engines.com/en/system/Qdrant) cloud-native data base.

Uses Rust as main system language

# Queries

Like it was mentioned before Qdrant is no-sql db with OpenAPI v3 and multiple programming language support.

Let's see some query examples:

## Instalation

```shell
docker pull qdrant/qdrant

docker run -p 6333:6333 -p 6334:6334 \
    -v $(pwd)/qdrant_storage:/qdrant/storage:z \
    qdrant/qdrant

```

Under the default configuration all data will be stored in the ./qdrant_storage directory. This will also be the only directory that both the Container and the host machine can both see.

Qdrant is now accessible:

1) REST API: localhost:6333
2) Web UI: localhost:6333/dashboard
3) GRPC API: localhost:6334

Freaquently I'm too dumb to use rust-client (but i'm trying my best at MIPT's rust cource!), so let's try rest-api

create collection
```shell
curl -X PUT 'http://localhost:6333/collections/test_collection' \
  -H 'Content-Type: application/json' \
  --data-raw '{
    "vectors": {
      "size": 4,
      "distance": "Dot"
    }
  }'
{"result":true,"status":"ok","time":5.309032706} 
```

let's look at the result

```shell
curl 'http://localhost:6333/collections/test_collection'
{
    "result": {
        "status": "green",
        "optimizer_status": "ok",
        "vectors_count": 0,
        "indexed_vectors_count": 0,
        "points_count": 0,
        "segments_count": 4,
        "config": {
            "params": {
                "vectors": {
                    "size": 4,
                    "distance": "Dot"
                },
                "shard_number": 1,
                "replication_factor": 1,
                "write_consistency_factor": 1,
                "on_disk_payload": true
            },
            "hnsw_config": {
                "m": 16,
                "ef_construct": 100,
                "full_scan_threshold": 10000,
                "max_indexing_threads": 0,
                "on_disk": false
            },
            "optimizer_config": {
                "deleted_threshold": 0.2,
                "vacuum_min_vector_number": 1000,
                "default_segment_number": 0,
                "max_segment_size": null,
                "memmap_threshold": null,
                "indexing_threshold": 20000,
                "flush_interval_sec": 5,
                "max_optimization_threads": null
            },
            "wal_config": {
                "wal_capacity_mb": 32,
                "wal_segments_ahead": 0
            },
            "quantization_config": null
        },
        "payload_schema": {}
    },
    "status": "ok",
    "time": 0.19127214
}
```

let's put some data into our collection

```shell
curl -X PUT 'http://localhost:6333/collections/test_collection/points?wait=true' -H 'Content-Type: application/json' -d \
'{
  "points": [
    {
      "id": 1,
      "vector": [0.05, 0.61, 0.76, 0.74],
      "payload": {"city": "Berlin"}
    },
    {
      "id": 2,
      "vector": [0.19, 0.81, 0.75, 0.11],
      "payload": {"city": "London"}
    },
    {
      "id": 3,
      "vector": [0.36, 0.55, 0.47, 0.94],
      "payload": {"city": "Moscow"}
    },
    {
      "id": 4,
      "vector": [0.18, 0.01, 0.85, 0.80],
      "payload": {"city": "New York"}
    },
    {
      "id": 5,
      "vector": [0.24, 0.18, 0.22, 0.44],
      "payload": {"city": "Beijing"}
    },
    {
      "id": 6,
      "vector": [0.35, 0.08, 0.11, 0.44],
      "payload": {"city": "Mumbai"}
    }
  ]
}'
{"result":{"operation_id":0,"status":"completed"},"status":"ok","time":0.176862847}   
```

we can see now that vector count became 6
```shell
curl 'http://localhost:6333/collections/test_collection' | jq                                                                     
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   769  100   769    0     0   278k      0 --:--:-- --:--:-- --:--:--  375k
{
  "result": {
    "status": "green",
    "optimizer_status": "ok",
    "vectors_count": 6,
    "indexed_vectors_count": 0,
    "points_count": 6,
    "segments_count": 4,
    "config": {
      "params": {
        "vectors": {
          "size": 4,
          "distance": "Dot"
        },
        "shard_number": 1,
        "replication_factor": 1,
        "write_consistency_factor": 1,
        "on_disk_payload": true
      },
      "hnsw_config": {
        "m": 16,
        "ef_construct": 100,
        "full_scan_threshold": 10000,
        "max_indexing_threads": 0,
        "on_disk": false
      },
      "optimizer_config": {
        "deleted_threshold": 0.2,
        "vacuum_min_vector_number": 1000,
        "default_segment_number": 0,
        "max_segment_size": null,
        "memmap_threshold": null,
        "indexing_threshold": 20000,
        "flush_interval_sec": 5,
        "max_optimization_threads": null
      },
      "wal_config": {
        "wal_capacity_mb": 32,
        "wal_segments_ahead": 0
      },
      "quantization_config": null
    },
    "payload_schema": {}
  },
  "status": "ok",
  "time": 0.000029154
}
```


```shell
curl -X POST http://localhost:6333/collections/test_collection/points/search -H 'Content-Type: application/json' -d '{"vector": [0.2, 0.1, 0.9, 0.7], "limit": 3, "with_payload": true}' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   344  100   278  100    66  85171  20220 --:--:-- --:--:-- --:--:--  111k
{
  "result": [
    {
      "id": 4,
      "version": 0,
      "score": 1.362,
      "payload": {
        "city": "New York"
      },
      "vector": null
    },
    {
      "id": 1,
      "version": 0,
      "score": 1.273,
      "payload": {
        "city": "Berlin"
      },
      "vector": null
    },
    {
      "id": 3,
      "version": 0,
      "score": 1.208,
      "payload": {
        "city": "Moscow"
      },
      "vector": null
    }
  ],
  "status": "ok",
  "time": 0.000670676
}
```
as we can see db supports easy-to-use interface for search of close vectors (by metrics)


we are also able to filter data by additional values
```shell
curl "http://localhost:6333/collections/test_collection/points/$(curl -X POST 'http://localhost:6333/collections/test_collection/points/search' -H 'Content-Type: application/json' -d '{
    "filter": {
        "should": [
            {
                "key": "city",
                "match": { "value": "Beijing"} 
            }
        ]
    },
    "vector": [0.2, 0.1, 0.9, 0.7],
    "top": 1
}' | jq | grep \"id\" | tail -c 3 | head -c -2)" | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   314  100   107  100   207  17925  34679 --:--:-- --:--:-- --:--:-- 62800
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   112  100   112    0     0  45454      0 --:--:-- --:--:-- --:--:-- 56000
{
  "result": {
    "id": 5,
    "payload": {
      "city": "Beijing"
    },
    "vector": [
      0.24,
      0.18,
      0.22,
      0.44
    ]
  },
  "status": "ok",
  "time": 0.000058001
}
```


let's now remove our only point and repeat query

```shell
curl -X POST 'http://localhost:6333/collections/test_collection/points/delete' -H "Content-type: application/json" -d '{ "points": [5] }'
{"result":{"operation_id":1,"status":"acknowledged"},"status":"ok","time":0.013389991}                                                                                                                                                                                    
curl "http://localhost:6333/collections/test_collection/points/$(curl -X POST 'http://localhost:6333/collections/test_collection/points/search' -H 'Content-Type: application/json' -d '{
    "filter": {
        "should": [
            {
                "key": "city",
                "match": { "value": "Beijing"} 
            }
        ]
    },
    "vector": [0.2, 0.1, 0.9, 0.7],
    "top": 3
}' | jq | grep \"id\" | tail -c 3 | head -c -2)" | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   253  100    46  100   207  16570  74567 --:--:-- --:--:-- --:--:--  123k
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
```

now we see empty result

let's create index
```shell
curl -X PUT 'http://localhost:6333/collections/test_collection/index' -H 'Content-type: application/json' -d '{ "field_name": "payload", "field_schema": "text"}'
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   136  100    86  100    50   1201    698 --:--:-- --:--:-- --:--:--  1915
{
  "result": {
    "operation_id": 5,
    "status": "acknowledged"
  },
  "status": "ok",
  "time": 0.066981548
}
```
<!-- do all the shit  -->

# Some useful notes about queries

## Transactions

Qdrant is not intended to have strong transaction guarantees, which allows it to perform point operations with low overhead.

Here are some notes about [cluster deployment](https://qdrant.tech/documentation/guides/distributed_deployment/) and [work with distributed data](https://qdrant.tech/articles/dedicated-service/).


## [Query planning](https://qdrant.tech/documentation/concepts/search/#query-planning)

The strategy selection process relies heavily on heuristics and can vary from release to release. However, the general principles are:

1) planning is performed for each segment independently (see storage for more information about segments)
2) prefer a full scan if the amount of points is below a threshold
3) estimate the cardinality of a filtered result before selecting a strategy
4) retrieve points using payload index (see indexing) if cardinality is below threshold
5) use filterable vector index if the cardinality is above a threshold

## [Storing options](https://qdrant.tech/documentation/concepts/storage/#vector-storage)

1) In-memory storage - Stores all vectors in RAM, has the highest speed since disk access is required only for persistence.

2) Memmap storage - Creates a virtual address space associated with the file on disk. Wiki. Mmapped files are not directly loaded into RAM. Instead, they use page cache to access the contents of the file. This scheme allows flexible use of available memory. With sufficient RAM, it is almost as fast as in-memory storage.

## [Indexes](https://qdrant.tech/documentation/concepts/indexing/)

Types of indexes that are supported by qdrant:
1) [Payload Index](https://qdrant.tech/documentation/concepts/indexing/#payload-index)
2) [Full-text index](https://qdrant.tech/documentation/concepts/indexing/#full-text-index)
3) [Parameterized index](https://qdrant.tech/documentation/concepts/indexing/#parameterized-index)
4) [Vector Index](https://qdrant.tech/documentation/concepts/indexing/#vector-index)
5) [Sparse Vector Index](https://qdrant.tech/documentation/concepts/indexing/#sparse-vector-index)

## [Sharding](https://qdrant.tech/documentation/guides/distributed_deployment/#sharding)

Qdrant supports 2 types of shards:
1) Automatic sharding: Points are distributed among shards by using a consistent hashing algorithm, so that shards are managing non-intersecting subsets of points. This is the default behavior.
2) User-defined sharding: Available as of v1.7.0 - Each point is uploaded to a specific shard, so that operations can hit only the shard or shards they need. Even with this distribution, shards still ensure having non-intersecting subsets of points. 

Each node knows where all parts of the collection are stored through the [consensus protocol](https://qdrant.tech/documentation/guides/distributed_deployment/#raft), so when you send a search request to one Qdrant node, it automatically queries all other nodes to obtain the full search result.

Qdrant allows [moving shards](https://qdrant.tech/documentation/guides/distributed_deployment/#moving-shards) between nodes in the cluster and removing nodes from the cluster. This functionality unlocks the ability to dynamically scale the cluster size without downtime. It also allows you to upgrade or migrate nodes without downtime.

## Recovery & [snapshots](https://qdrant.tech/documentation/concepts/snapshots/)

1) [Recovering from a URL or local file](https://qdrant.tech/documentation/concepts/snapshots/#recover-from-a-url-or-local-file) (useful for restoring a snapshot file that is on a remote server or already stored on the node)
2) [Recovering from an uploaded file](https://qdrant.tech/documentation/concepts/snapshots/#recover-from-an-uploaded-file) (useful for migrating data to a new cluster)
3) [Recovering during start-up](https://qdrant.tech/documentation/concepts/snapshots/#recover-during-start-up) (useful when running a self-hosted single-node Qdrant instance)

# Data Mining, Data Warehousing & OLAP?

I think this terms can be applied to qdrant-db because it is distributed system that supports analitics of large amounts of data, that can be unified by
vector-metrics. So this data base can be used like Data Warehouse. It also is used for deep learning purposes (Data Mining), and of cource it supports OLAP 
because it is verctor-type db.

# Security

You can read about it [here](https://qdrant.tech/documentation/guides/security/) to dive in, but main points are that qdrant supports simple form of client authentication using a static API key and TLS for encrypted connections can be enabled on your Qdrant instance to secure connections.

[Some notes about security policy](https://app.drata.com/trust/9cbbb75b-0c38-11ee-865f-029d78a187d9)

# Contriibuting

See [repo](https://github.com/qdrant/qdrant/blob/master/CONTRIBUTING.md) for more information, but it should be mentioned, that
qdrant is opensource project which is licensed under [Apache licence](https://github.com/qdrant/qdrant/blob/master/LICENSE) 

# Available datasets

https://qdrant.tech/documentation/datasets/

let's create our own dataset:

```shell
# script.sh
curl -X PUT 'http://localhost:6333/collections/test_collection/points?wait=true' -H 'Content-Type: application/json' -d \
"$(echo "$(echo "{ \"points\": [ $(for id in {0..500}; do 
        echo \{
        echo \"id\": $id,
        echo \"vector\": \[0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc), 0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc), 0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc), 0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc)\],
        echo \"payload\": \{\"city\": \"$(( $id % 5 ))\"\}
        echo \},
    done
        echo \{
        echo \"id\": 500,
        echo \"vector\": \[0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc), 0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc), 0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc), 0$(echo "scale=2 ; $(od -An -N2 -i /dev/urandom) / 65536" | bc)\],
        echo \"payload\": \{\"city\": \"$(( $id % 5 ))\"\};
        echo \}
    )
]
}")" | jq)"
```

run it(surprisingly zsh is very slow at dividing numbers and taking random bits): 
```shell
./script.sh
{"result":{"operation_id":7,"status":"completed"},"status":"ok","time":0.123003621}  
```

let's create a snapshot with our collection
```shell
curl -X POST 'http://localhost:6333/collections/test_collection/snapshots'
{"result":{"name":"test_collection-5099174293936986-2024-04-16-01-27-55.snapshot","creation_time":"2024-04-16T01:27:59","size":67408896,"checksum":"4c037c0d2e791807bcda962122b83bff3972f2ec8e7321209e2bc50d1add8b13"},"status":"ok","time":3.762199028}
```

It is available in the root of the project in qdrant_storage.

# Documentation & FAQ

Documentation is available [here](https://qdrant.tech/documentation/)

This db has very good documentation and very intuitive site, which is very easy to work with.
All API's have plenty of examples, and also documentation contains section with datasets so learning so about communication with this db is pretty handy with it's [docs](https://qdrant.github.io/qdrant/redoc/index.html) and [blogs](https://qdrant.tech/articles/).

There are also links to [github repo](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/quick-start.md) and [FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/) there. 


# PS

In my mind I see this topic to be consistent so some parts of the given task may be swaped with other, but I strongly believe that all of them can be found :)